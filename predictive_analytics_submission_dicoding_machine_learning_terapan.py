# -*- coding: utf-8 -*-
"""Predictive Analytics Submission - Dicoding Machine Learning Terapan

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x6VnnVtdO1chRe65mdd7kEecBh1-Tuya

# Prediksi Biaya Asuransi Kesehatan
"""

# Commented out IPython magic to ensure Python compatibility.
# Import library
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

# Menghubungkan google drive ke google colab
from google.colab import drive
drive.mount('/content/drive')

# Load the dataset
# src https://www.kaggle.com/datasets/mirichoi0218/insurance
df_path = '/content/drive/MyDrive/medical_insurance_cost.csv'
df = pd.read_csv(df_path)
df

"""## Exploratory Data Analysis (Deskripsi Variabel)

Variabel-variabel yang ada pada dataset Obesity di atas adalah sebagai berikut:
* charges (Target): merepresentasikan tagihan biaya rumah sakit.
* age: merepresentasikan umur.
* sex: merepresentasikan jenis kelamin.
* bmi: merepresentasikan nilai keidealan berat tubuh seseorang (18.5 ≤ BMI < 24.9 → Normal)
* children: merepresentasikan jumlah anak yang dimiliki.
* smoker: merepresentasikan perokok atau tidak (yes/no).
* region: merepresentasikan wilayah geografis tempat tinggal.

Setelah memahami deskripsi dari tiap variabel pada dataset. Selanjutnya adalah mengecek informasi dari dataset menggunakan fungsi info().
"""

df.info()

"""Dari output dapat dilihat bahwa:
* Terdapat 3 kolom dengan tipe data object, yaitu: sex, smoker dan region (Fitur non-numerik).
* Terdapat 2 kolom dengan tipe data float dan 2 kolom dengan tipe data int, yaitu: bmi dan charges untuk tipe data float dan age dan chilren untuk tipe data int
 (Fitur numerik).

Setelah ditelusuri, tidak ada yang salah dengan tipe data. Selanjutnya, mari cek deskripsi statistik data dengan fungsi describe().
"""

df.describe()

"""Seperti yang dapat dilihat, fungsi describe() memberikan informasi statistik seperti:
* Count adalah jumlah sampel pada data.
* Mean adalah nilai rata-rata.
* Std adalah standar deviasi.
* Min yaitu nilai minimum setiap kolom.
* 25% adalah kuartil pertama. (Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama)
* 50% adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
* 75% adalah kuartil ketiga.
* Max adalah nilai maksimum.

## Exploratory Data Analysis (Menangani Missing Value dan Outliers)

### Menangani Missing Value

Sebelum beranjak lebih jauh kita perlu mengatasi missing value jika ada. Mari lihat apakah ada missing value dengan menjalankan kode berikut.
"""

df.isnull().values.any()

"""Ternyata False, itu artinya dataset ini tidak memiliki missing value.

### Menangani Outliers

Selain missing value, kita juga perlu menangani outliers jika ada. Mari visualisasikan beberapa data untuk melihat apakah ada outliers pada dataset ini. Mari lihat data apa yang bisa divisualisasikan dengan fungsi describe().
"""

df.describe()

"""Visualisasikan data medical_insurance_cost dengan boxplot untuk mendeteksi outliers pada fitur numerik."""

# age
sns.boxplot(x=df['age'])

# bmi
sns.boxplot(x=df['bmi'])

# children
sns.boxplot(x=df['children'])

"""Dari apa yang dapat dilihat ternyata ada outliers. Mari implementasikan metode Inter Quartile Range (IQR) untuk mengatasi outliers."""

numeric_features = ['age', 'bmi', 'children', 'charges']

Q1 = df[numeric_features].quantile(0.25)
Q3 = df[numeric_features].quantile(0.75)
IQR = Q3 - Q1
df = df[~((df[numeric_features]<(Q1-1.5*IQR))|(df[numeric_features]>(Q3+1.5*IQR))).any(axis=1)]

# Cek ukuran dataset setelah drop outliers
df.shape

"""Dari sebelumnya memiliki 1338 row data sekarang menjadi 1193 karena beberapa row memiliki outliers.

## Exploratory Data Analysis (Univariate Analysis)

Sebelum melangkah lebih jauh, kita perlu melakukan analisis pada satu variabel dalam satu waktu. Hal ini bertujuan agar kita dapat memahami distribusi data, seperti apakah data tersebut normal atau tidak.

Bagi fitur pada dataset menjadi dua bagian, yaitu numerical features dan categorical features
"""

numerical_features = ['age', 'bmi', 'children', 'charges']
categorical_features = ['sex', 'smoker', 'region']

"""Pertama, lakukan analisis terhadap fitur kategori.

### Categorical Features
"""

# sex
feature = categorical_features[0]
count = df[feature].value_counts()
percentage = 100*df[feature].value_counts(normalize=True)
df_sex = pd.DataFrame({"Jumlah sampel":count, "Persentase":percentage.round(1)})
print(df_sex)
count.plot(kind='bar', title=feature)

# smoker
feature = categorical_features[1]
count = df[feature].value_counts()
percentage = 100*df[feature].value_counts(normalize=True)
df_smoker = pd.DataFrame({"Jumlah sampel":count, "Persentase":percentage.round(1)})
print(df_smoker)
count.plot(kind='bar', title=feature)

# region
feature = categorical_features[2]
count = df[feature].value_counts()
percentage = 100*df[feature].value_counts(normalize=True)
df_region = pd.DataFrame({"Jumlah sampel":count, "Persentase":percentage.round(1)})
print(df_region)
count.plot(kind='bar', title=feature)

"""### Numerical Features

Setelah menganalisis fitur kategori, selanjutnya menganalisis fitur numerik.
"""

df.hist(bins=50, figsize=(20,15))
plt.show()

"""## Exploratory Data Analysis (Multivariate Analysis)

### Categorical Features

Cek rata-rata biaya terhadap masing-masing fitur untuk mengetahui pengaruh fitur kategori terhadap biaya.
"""

cat_features = df.select_dtypes(include='object').columns.to_list()

for col in cat_features:
  sns.catplot(x=col, y='charges', kind='bar', dodge=False, height=4, aspect=3, data=df, palette='Set3')
  plt.title("Rata-rata 'charges' Relatif terhadap - {}".format(col))

"""Dengan mengamati rata-rata biaya relatif terhadap fitur kategori di atas, kita memperoleh insight sebagai berikut:
* Pada fitur 'sex', rata-rata biaya untuk laki-laki dan perempuan terlihat hampir sama. Hal ini menunjukkan bahwa 'sex' bukan faktor utama yang mempengaruhi biaya kesehatan.
* Pada fitur 'smoker', perokok memiliki rata-rata biaya yang lebih tinggi daripada yang non-perokok. Perbedaan ini menunjukkan bahwa merokok memiliki dampak besar terhadap peningkatan biaya kesehatan.
* Pada fitur 'region', rata-rata biaya kesehatan di tiap wilayah berbeda-beda, tetapi tidak menunjukkan perbedaan yang begitu signifikan.


Kesimpulannya, fitur 'smoker' memiliki dampak besar terhadap peningkatan biaya kesehatan. Fitur 'sex' tidak begitu memiliki pengaruh yang signifikan. Dan fitur 'region' memiliki pengaruh, namun tidak sebesar fitur 'smoker'.

### Numerical Features
"""

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(df, diag_kind = 'kde')

"""Berdasarkan pairplot yang ditampilkan, berikut beberapa insight yang diperoleh:
* Fitur age dan charges: Terdapat pola melengkung yang menunjukkan bahwa semakin tua usia pasiennya, kemungkinan biaya kesehatannya juga akan semakin tinggi.
* Fitur bmi dan charges: Terlihat beberapa pola yang menunjukkan bahwa pasien dengan BMI lebih tinggi cenderung memiliki biaya yang lebih tinggi juga.
* Fitur children dan charges: Data menunjukkan distribusi yang cukup merata. Sehingga, tampaknya tidak ada korelasi yang kuat antara fitur children dan charges.

Dari insight di atas, kemungkinan besar faktor utama yang mempengaruhi biaya (charges) adalah fitur age dan bmi.

Untuk mengukur skor korelasinya, mari gunakan fungsi corr()
"""

plt.figure(figsize=(10, 8))
correlation_matrix = df[numerical_features].corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Berdasarkan Correlation Matrix yang ditampilkan di atas, berikut beberapa insight yang dapat diperoleh:
* Korelasi fitur age dan charges (0.44): Terdapat korelasi positif sedang antara age dan charges. Ini menunjukkan semakin tua seseorang, semakin besar pula biaya kesehatannya.
* Korelasi fitur bmi dan charges (-0.06): Korelasi antara bmi dan charges sangatlah kecil, bahkan negatif. Kita mengharapkan korelasi ini bernilai positif, karena BMI yang lebih tinggi sering dikaitkan dengan resiko penyakit. Namun, korelasi kecil ini dapat terjadi jika faktor lain, seperti merokok memiliki pengaruh lebih besar terhadap biaya.
* Korelasi fitur children dan charges (0.08): Gambar di atas menunjukkan hampir tidak ada korelasi antara children dan charges. Sehingga, memiliki lebih banyak anak tidak secara langsung meningkatkan biaya kesehatan seseorang.

Dari insight di atas, kesimpulan yang dapat diambil adalah:
* Fitur age merupakan fitur numerik yang paling mempengaruhi biaya kesehatan.
* Fitur bmi dan children memiliki pengaruh yang kecil terhadap biaya kesehatan.
* Ada kemungkinan bahwa faktor kategorikal (seperti fitur smoker yang terlihat sangat berpengaruh pada grafik sebelumnya) lebih menentukan biaya kesehatan seseorang daripada fitur numerik.

Dari kesimpulan di atas dapat dilihat bahwa fitur children memiliki pengaruh yang sangat kecil terhadap biaya. Sehingga, fitur tersebut dapat di-drop.
"""

df.drop(['children'], inplace=True, axis=1)
df.head()

"""## Data Preparation

### Encoding Fitur Kategori

Agar model kita dapat memproses fitur kategori, kita perlu melakukan encoding terhadap fitur kategori. Pada fitur sex dan smoker akan kita lakukan label encoding, karena kedua fitur ini hanya memiliki 2 kategori (male dan female untuk kategori sex, yes dan no untuk kategori smoker). Dan one hot encoding untuk fitur region karena memiliki lebih dari 2 kategori (northeast, southeast, northwest, southwest).
"""

from sklearn.preprocessing import LabelEncoder, OneHotEncoder

# Label Encoding untuk fitur sex dan smoker
le = LabelEncoder()
df['sex'] = le.fit_transform(df['sex']) # female = 0, male = 1
df['smoker'] = le.fit_transform(df['smoker']) # no = 0, yes = 1

# One Hot Encoding untuk region
ohe = OneHotEncoder(drop='first', sparse_output=False)
encoded_region = ohe.fit_transform(df[['region']])

# Konversi hasil encoding ke DataFrame dan pastikan index tetap sama
encoded_region_df = pd.DataFrame(encoded_region, columns=ohe.get_feature_names_out(['region']))
encoded_region_df.index = df.index  # Pastikan index tetap sama agar tidak menyebabkan NaN pada beberapa baris

# Gabungkan dengan dataset utama
df_final = pd.concat([df.drop(columns=['region']), encoded_region_df], axis=1)

# Pastikan semua kolom hasil encoding dalam format integer
df_final[encoded_region_df.columns] = df_final[encoded_region_df.columns].astype(int)

# Cek hasil encoding
df_final.head()

"""Setelah melakukan encoding seperti di atas, fitur kategori akan menjadi:
* sex

  female = 0, male = 1
* smoker

  no= 0, yes = 1
* region

  northeast = [0, 0, 0]

  northwest = [1, 0, 0]

  southeast = [0, 1, 0]
  
  southwest = [0, 0, 1]

### Train-Test Split

Tahap selanjutnya adalah melakukan train-test split. Karena jumlah data yang dimiliki cukup banyak, kita kan menggunakan proporsi pembagian sebesar 80:20.
"""

df_final.shape

from sklearn.model_selection import train_test_split

X = df_final.drop(['charges'], axis=1)
y = df_final['charges']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train set: {len(X_train)}')
print(f'Total # of sample in test set: {len(X_test)}')

"""### Standarisasi

Pada proyek ini, kita akan menggunakan algoritma XGBoost. Jadi, fitur seperti age dan bmi tidak perlu distandarisasi karena XGBoost tidak bergantung pada skala fitur. Dan juga, age dan bmi sudah memiliki skala dan arti medis yang jelas.
"""

df_final

"""## Model Development

### Inisialisasi Model

Di sini kita akan menggunakan algoritma XGBoost. Mari inisialisasi model terlebih dahulu.
"""

from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error

# Inisialisasi model
model = XGBRegressor(n_estimators=30, learning_rate=0.01, random_state=36)

"""Berikut adalah parameter yang digunakan:
* n_estimators: Jumlah trees (pohon) dalam boosting.
* learning_rate: Mengontrol seberapa besar perubahan yang dilakukan oleh setiap pohon baru terhadap model sebelumnya.
* random_state: digunakan untuk mengontrol keacakan dalam pelatihan model, sehingga hasil yang didapat konsisten setiap kali model dijalankan.
"""

# Latih model
model.fit(X_train, y_train)

"""### Evaluasi Model

Mari kita evaluasi model kita menggunakan metrik MSE dengan kode berikut.
"""

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['XGB'])

# Hitung Mean Squared Error algoritma pada data train dan test
mse.loc['XGB', 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e8
mse.loc['XGB', 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e8

# Panggil mse
mse

"""Untuk memudahkan, mari kita plot metrik tersebut dengan bar chart dengan kode berikut."""

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""Untuk menguji model yang telah diinisialisasi, mari jalankan kode berikut."""

prediksi = X_test.iloc[:10].copy()
pred_dict = {'y_true':y_test[:10]}
pred_dict['y_pred'] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""### Hyperparameter Tuning

Setelah melihat uji model seperti pada tabel di atas, dapat disimpulkan bahwa model belum begitu baik kinerjanya. Hal ini dapat dilihat dari nilai 'y_pred' yang masih terlampau jauh dari 'y_true'. Maka dari itu, selanjutnya kita akan melakukan hyperparameter tuning. Pada proyek ini, metode yang digunakan adalah Grid Search.
"""

from sklearn.model_selection import GridSearchCV

# Inisialisasi parameter yang akan dituning
param_grid = {
    'n_estimators': [100, 200, 300],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 4, 5],
    'min_child_weight': [1, 2, 3],
}

# Melakukan Grid Search
grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)

# Hasil terbaik
print("Best Parameters:", grid_search.best_params_)
print("Best Score (MSE):", grid_search.best_score_)

"""Setelah melakukan grid search terhadap parameter, selanjutnya kita akan memilih parameter yang terbaik dengan kode berikut."""

best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

"""Setelah memilih parameter terbaik, selanjutnya latih ulang model dengan parameter yang telah dipilih."""

final_model = XGBRegressor(**best_params)
final_model.fit(X_train, y_train)

"""Mari kita evaluasi ulang model kita."""

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['XGB'])

# Hitung Mean Squared Error algoritma pada data train dan test
mse.loc['XGB', 'train'] = mean_squared_error(y_true=y_train, y_pred=final_model.predict(X_train))/1e8
mse.loc['XGB', 'test'] = mean_squared_error(y_true=y_test, y_pred=final_model.predict(X_test))/1e8

# Panggil mse
mse

"""Lakukan plot ulang untuk melihat metrik dengan jelas."""

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""Dapat dilihat dari yang sebelumnya mse bernilai sekitar 0,36 pada train dan 0,35 pada test, sekarang hanya menjadi 0,18 pada train dan 0,16 pada test. Ini berarti kita telah berhasil melakukan hyperparameter tuning terhadap model dan kinerja model menjadi lebih baik.

Jalankan kode berikut untuk menguji ulang model yang telah dituning.
"""

prediksi = X_test.iloc[:10].copy()
pred_dict = {'y_true':y_test[:10]}
pred_dict['y_pred'] = final_model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)